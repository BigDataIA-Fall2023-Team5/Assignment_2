{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange; font-weight:bold\">Note: To answer questions based on text documents, we recommend the procedure in <a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\">Question Answering using Embeddings</a>. Some of the code below may rely on <a href=\"https://github.com/openai/openai-cookbook/tree/main/transition_guides_for_deprecated_API_endpoints\">deprecated API endpoints</a>.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a fine-tuning model specialized for Q&A\n",
    "This notebook will utilize the dataset of context, question and answer pairs to additionally create adversarial questions and context pairs, where the question was not generated on that context. In those cases the model will be prompted to answer \"No sufficient context for answering the question\". We will also train a discriminator model, which predicts whether the question can be answered based on the context or not.\n",
    "\n",
    "We will add hard adversarial examples as well, which will be based either on semantically similar sections, or neighbouring sections, originating from the same article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests>=2.20 (from openai)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from openai)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp (from openai)\n",
      "  Downloading aiohttp-3.8.6-cp38-cp38-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.20->openai)\n",
      "  Downloading charset_normalizer-3.3.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (32 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.20->openai)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests>=2.20->openai)\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.20->openai)\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->openai)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Downloading multidict-6.0.4-cp38-cp38-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Downloading yarl-1.9.2-cp38-cp38-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Downloading frozenlist-1.4.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp38-cp38-macosx_10_9_x86_64.whl (369 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.9/369.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.0-cp38-cp38-macosx_10_9_x86_64.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.0-cp38-cp38-macosx_10_9_x86_64.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, tqdm, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.3.0 frozenlist-1.4.0 idna-3.4 multidict-6.0.4 openai-0.28.1 requests-2.31.0 tqdm-4.66.1 urllib3-2.0.7 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.1-cp38-cp38-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.20.3 (from pandas)\n",
      "  Downloading numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.1-cp38-cp38-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, numpy, joblib, scipy, pandas, scikit-learn\n",
      "Successfully installed joblib-1.3.2 numpy-1.24.4 pandas-2.0.3 pytz-2023.3.post1 scikit-learn-1.3.1 scipy-1.10.1 threadpoolctl-3.2.0 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Description</th>\n",
       "      <th>Last_Updated</th>\n",
       "      <th>SEC_Number</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PDF_Link</th>\n",
       "      <th>pyPDF_extraction</th>\n",
       "      <th>tokens</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Application for registration or exemption from...</td>\n",
       "      <td>Feb. 1999</td>\n",
       "      <td>SEC1935</td>\n",
       "      <td>Self-Regulatory Organizations</td>\n",
       "      <td>https://www.sec.gov/files/form1-e.pdf</td>\n",
       "      <td>You may not send a completed printout of this ...</td>\n",
       "      <td>1581</td>\n",
       "      <td>1) What is the purpose of Form 1-E mentioned i...</td>\n",
       "      <td>1.The purpose of Form 1-E mentioned in the tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-A</td>\n",
       "      <td>Regulation A Offering Statement (PDF)</td>\n",
       "      <td>Sept. 2021</td>\n",
       "      <td>SEC486</td>\n",
       "      <td>Securities Act of 1933, Small Businesses</td>\n",
       "      <td>https://www.sec.gov/files/form1-k.pdf</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1. What is the purpose of Form 1-K?\\n2. What a...</td>\n",
       "      <td>1.The purpose of Form 1-K is to provide an ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-E</td>\n",
       "      <td>Notification under Regulation E (PDF)</td>\n",
       "      <td>Aug. 2001</td>\n",
       "      <td>SEC1807</td>\n",
       "      <td>Investment Company Act of 1940, Small Business...</td>\n",
       "      <td>https://www.sec.gov/files/form1-n.pdf</td>\n",
       "      <td>OMB APPROVAL OMB Number 3235 0554 Expires Febr...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1. What is the purpose of Form 1-N?\\n\\n2. How ...</td>\n",
       "      <td>1.The purpose of Form 1-N is to serve as a not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-K</td>\n",
       "      <td>Annual Reports and Special Financial Reports (...</td>\n",
       "      <td>Sept. 2021</td>\n",
       "      <td>SEC2913</td>\n",
       "      <td>Securities Act of 1933, Small Businesses</td>\n",
       "      <td>https://www.sec.gov/files/form1-sa.pdf</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1. What is the purpose of Form 1 SA?\\n2. How o...</td>\n",
       "      <td>1.The purpose of Form 1 SA is to file semiannu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-N</td>\n",
       "      <td>Form and amendments for notice of registration...</td>\n",
       "      <td>Dec. 2013</td>\n",
       "      <td>SEC2568</td>\n",
       "      <td>Securities Exchange Act of 1934, Self-Regulato...</td>\n",
       "      <td>https://www.sec.gov/files/form1-u.pdf</td>\n",
       "      <td>OMB APPROVAL OMB Number 3235 0722 Expires Dece...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1. What is the purpose of Form 1-U?\\n\\n2. What...</td>\n",
       "      <td>1.The purpose of Form 1-U is to file a current...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number                                        Description Last_Updated  \\\n",
       "0      1  Application for registration or exemption from...    Feb. 1999   \n",
       "1    1-A              Regulation A Offering Statement (PDF)   Sept. 2021   \n",
       "2    1-E              Notification under Regulation E (PDF)    Aug. 2001   \n",
       "3    1-K  Annual Reports and Special Financial Reports (...   Sept. 2021   \n",
       "4    1-N  Form and amendments for notice of registration...    Dec. 2013   \n",
       "\n",
       "  SEC_Number                                              Topic  \\\n",
       "0    SEC1935                      Self-Regulatory Organizations   \n",
       "1     SEC486           Securities Act of 1933, Small Businesses   \n",
       "2    SEC1807  Investment Company Act of 1940, Small Business...   \n",
       "3    SEC2913           Securities Act of 1933, Small Businesses   \n",
       "4    SEC2568  Securities Exchange Act of 1934, Self-Regulato...   \n",
       "\n",
       "                                 PDF_Link  \\\n",
       "0   https://www.sec.gov/files/form1-e.pdf   \n",
       "1   https://www.sec.gov/files/form1-k.pdf   \n",
       "2   https://www.sec.gov/files/form1-n.pdf   \n",
       "3  https://www.sec.gov/files/form1-sa.pdf   \n",
       "4   https://www.sec.gov/files/form1-u.pdf   \n",
       "\n",
       "                                    pyPDF_extraction  tokens  \\\n",
       "0  You may not send a completed printout of this ...    1581   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...    2000   \n",
       "2  OMB APPROVAL OMB Number 3235 0554 Expires Febr...    2000   \n",
       "3  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...    2000   \n",
       "4  OMB APPROVAL OMB Number 3235 0722 Expires Dece...    2000   \n",
       "\n",
       "                                           questions  \\\n",
       "0  1) What is the purpose of Form 1-E mentioned i...   \n",
       "1  1. What is the purpose of Form 1-K?\\n2. What a...   \n",
       "2  1. What is the purpose of Form 1-N?\\n\\n2. How ...   \n",
       "3  1. What is the purpose of Form 1 SA?\\n2. How o...   \n",
       "4  1. What is the purpose of Form 1-U?\\n\\n2. What...   \n",
       "\n",
       "                                             answers  \n",
       "0  1.The purpose of Form 1-E mentioned in the tex...  \n",
       "1  1.The purpose of Form 1-K is to provide an ann...  \n",
       "2  1.The purpose of Form 1-N is to serve as a not...  \n",
       "3  1.The purpose of Form 1 SA is to file semiannu...  \n",
       "4  1.The purpose of Form 1-U is to file a current...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/anamikabharali/Documents/UNI/BD/Assignment2/form_qa.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the sections into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we check that the separator we intend to use isn't present within the contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pyPDF_extraction.str.contains('->').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create the fine-tuning datasets for Q&A and discriminator models\n",
    "The fine-tuning dataset is created in the following way. For every corresponding question, answer and context pair we create:\n",
    "- Positive example: correct question, answer, context pair\n",
    "- Negative examples:\n",
    "  - random negative example, where the random context is paired with the question \n",
    "  - two hard negative examples\n",
    "    - one originating from the same wikipedia article\n",
    "    - another, which is most similar to the correct context\n",
    "\n",
    "This process is noisy, as sometimes the question might be answerable given a different context, but on average we hope this won't affect the peformance too much.\n",
    "\n",
    "We apply the same process of dataset creation for both the discriminator, and the Q&A answering model. We apply the process separately for the training and testing set, to ensure that the examples from the training set don't feature within the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answers'] = df['answers'].astype('string')\n",
    "\n",
    "df['questions'] = df['questions'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "string[python]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_similar_contexts(question, pyPDF_extraction, search_model='ada', max_rerank=10):\n",
    "    \"\"\"\n",
    "    Find similar contexts to the given context using the search file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = openai.Engine(search_model).search(\n",
    "            search_model=search_model, \n",
    "            query=question, \n",
    "            max_rerank=max_rerank,\n",
    "            #file=file_id\n",
    "        )\n",
    "        candidates = []\n",
    "        for result in results['data'][:3]:\n",
    "            if result['text'] == pyPDF_extraction:\n",
    "                continue\n",
    "            candidates.append(result['text'])\n",
    "        random_candidate = random.choice(candidates)\n",
    "        return random_candidate\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "def create_fine_tuning_dataset(df, discriminator=False, n_negative=1, add_related=False):\n",
    "    \"\"\"\n",
    "    Create a dataset for fine tuning the OpenAI model; either for a discriminator model, \n",
    "    or a model specializing in Q&A, where it says if no relevant context is found.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The dataframe containing the question, answer and context pairs\n",
    "    discriminator: bool\n",
    "        Whether to create a dataset for the discriminator\n",
    "    n_negative: int\n",
    "        The number of random negative samples to add (using a random context)\n",
    "    add_related: bool\n",
    "        Whether to add the related contexts to the correct context. These are hard negative examples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataframe containing the prompts and completions, ready for fine-tuning\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        for q, a in zip((str(\"1.\") + str(row['questions'])).split('\\n'), (str(\"1.\") + str(row['answers'])).split('\\n')):\n",
    "            #(\"1.\" + row.questions).split('\\n'), (\"1.\" + row.answers).split('\\n')\n",
    "            if len(q) >10 and len(a) >10:\n",
    "                if discriminator:\n",
    "                    rows.append({\"prompt\":f\"{row.pyPDF_extraction}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" yes\"})\n",
    "                else:\n",
    "                    rows.append({\"prompt\":f\"{row.pyPDF_extraction}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" {a[2:].strip()}\"})\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for q in (str(\"1.\") + str(row['questions'])).split('\\n'):\n",
    "            if len(q) >10:\n",
    "                for j in range(n_negative + (2 if add_related else 0)):\n",
    "                    random_context = \"\"\n",
    "                    if j == 0 and add_related:\n",
    "                        # add the related contexts based on originating from the same wikipedia page\n",
    "                        subset = df[(df.Description == row.Description) & (df.pyPDF_extraction != row.pyPDF_extraction)]\n",
    "                        \n",
    "                        if len(subset) < 1:\n",
    "                            continue\n",
    "                        random_context = subset.sample(1).iloc[0].pyPDF_extraction\n",
    "                    if j == 1 and add_related:\n",
    "                        # add the related contexts based on the most similar contexts according to the search\n",
    "                        random_context = get_random_similar_contexts(q[2:].strip(), row.pyPDF_extraction, search_model='ada', max_rerank=10)\n",
    "                    else:\n",
    "                        while True:\n",
    "                            # add random context, which isn't the correct context\n",
    "                            random_context = df.sample(1).iloc[0].pyPDF_extraction\n",
    "                            if random_context != row.pyPDF_extraction:\n",
    "                                break\n",
    "                    if discriminator:\n",
    "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" no\"})\n",
    "                    else:\n",
    "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" No appropriate context found to answer the question.\"})\n",
    "\n",
    "    return pd.DataFrame(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same process of dataset creation for both the discriminator, and the Q&A answering model. We apply the process separately for the training and testing set, to ensure that the examples from the training set don't feature within the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n",
      "search\n"
     ]
    }
   ],
   "source": [
    "for name, is_disc in [('discriminator', True), ('qa', False)]:\n",
    "    for train_test, dt in [('train', train_df), ('test', test_df)]:\n",
    "        ft = create_fine_tuning_dataset(dt, discriminator=is_disc, n_negative=1, add_related=True)\n",
    "        ft.to_json(f'{name}_{train_test}.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We formatted the data according to the recommendations from the fine-tuning tool, which is available using\n",
    "> openai tools fine_tunes.prepare_data -f qa_train.jsonl\n",
    "\n",
    "We highly recommend that you use this tool, which suggests improvements in your data formatting for fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Submit the datasets for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = getpass.getpass() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|████████████████████| 6.81M/6.81M [00:00<00:00, 6.76Git/s]\n",
      "Uploaded file from discriminator_train.jsonl: file-RVXPpCVbcAy8OYQd1FgM6Hp7\n",
      "Upload progress: 100%|████████████████████| 1.40M/1.40M [00:00<00:00, 1.72Git/s]\n",
      "Uploaded file from discriminator_test.jsonl: file-txvOjFVDiAx4IqJFhuVXlAYp\n",
      "Created fine-tune: ft-b3ZMvJsbq5RIODpFNxq51B0a\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-10-18 21:49:50] Created fine-tune: ft-b3ZMvJsbq5RIODpFNxq51B0a\n",
      "[2023-10-18 21:50:43] Fine-tune costs $2.09\n",
      "[2023-10-18 21:50:44] Fine-tune enqueued. Queue number: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"discriminator_train.jsonl\" -v \"discriminator_test.jsonl\" --batch_size 16  --compute_classification_metrics --classification_positive_class \" yes\" --model ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|████████████████████| 6.93M/6.93M [00:00<00:00, 6.58Git/s]\n",
      "Uploaded file from qa_train.jsonl: file-ddveIAIb5CcKxmNQMSSW2yXV\n",
      "Upload progress: 100%|████████████████████| 1.45M/1.45M [00:00<00:00, 2.28Git/s]\n",
      "Uploaded file from qa_test.jsonl: file-SefGfwAiJxHP9ReSv14RRXxx\n",
      "Created fine-tune: ft-JME7KM3hiNr3fQKp0zsPoKpk\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-10-18 21:51:35] Created fine-tune: ft-JME7KM3hiNr3fQKp0zsPoKpk\n",
      "[2023-10-18 21:52:25] Fine-tune failed. Fine-tune will exceed billing hard limit\n",
      "\n",
      "Job failed. Please contact us through our help center at help.openai.com if you need assistance.\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"qa_train.jsonl\" -v \"qa_test.jsonl\" --batch_size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Using the fine-tuned models\n",
    "\n",
    "We will now use the fine-tuned discriminator and the fine-tuned Q&A model. By requesting logprobs, we can see how certain the discriminator is in a `yes` vs `no` answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `curie:ft-openai-internal-2021-08-23-23-58-57` does not exist or you do not have access to it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mCompletion\u001b[39m.\u001b[39mcreate(model\u001b[39m=\u001b[39mdiscriminator_model, prompt\u001b[39m=\u001b[39mprompt, max_tokens\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, top_p\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, logprobs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtop_logprobs\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m apply_ft_discriminator(\u001b[39m'\u001b[39;49m\u001b[39mThe first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                         \u001b[39m'\u001b[39;49m\u001b[39mWhat was the first human-made object in space?\u001b[39;49m\u001b[39m'\u001b[39;49m, ft_discriminator)\n",
      "\u001b[1;32m/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb Cell 28\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mApply the fine tuned discriminator to a question, to assess whether it can be answered from the context.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcontext\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mQuestion: \u001b[39m\u001b[39m{\u001b[39;00mquestion\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Related:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49mdiscriminator_model, prompt\u001b[39m=\u001b[39;49mprompt, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, logprobs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anamikabharali/Documents/UNI/BD/Assignment2/Form-3-train-qa.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtop_logprobs\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/UNI/BD/Assignment2/.conda/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Documents/UNI/BD/Assignment2/.conda/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Documents/UNI/BD/Assignment2/.conda/lib/python3.8/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Documents/UNI/BD/Assignment2/.conda/lib/python3.8/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/UNI/BD/Assignment2/.conda/lib/python3.8/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The model `curie:ft-openai-internal-2021-08-23-23-58-57` does not exist or you do not have access to it."
     ]
    }
   ],
   "source": [
    "ft_discriminator = \"curie:ft-openai-internal-2021-08-23-23-58-57\"\n",
    "ft_qa = \"curie:ft-openai-internal-2021-08-23-17-54-10\"\n",
    "\n",
    "def apply_ft_discriminator(context, question, discriminator_model):\n",
    "    \"\"\"\n",
    "    Apply the fine tuned discriminator to a question, to assess whether it can be answered from the context.\n",
    "    \"\"\"\n",
    "    prompt = f\"{context}\\nQuestion: {question}\\n Related:\"\n",
    "    result = openai.Completion.create(model=discriminator_model, prompt=prompt, max_tokens=1, temperature=0, top_p=1, n=1, logprobs=2)\n",
    "    return result['choices'][0]['logprobs']['top_logprobs']\n",
    "\n",
    "apply_ft_discriminator('ABCD', \n",
    "                        'When?', ft_discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model can generalize well to different contexts and questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_ft_qa_answer(context, question, answering_model):\n",
    "    \"\"\"\n",
    "    Apply the fine tuned discriminator to a question\n",
    "    \"\"\"\n",
    "    prompt = f\"{context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    result = openai.Completion.create(model=answering_model, prompt=prompt, max_tokens=30, temperature=0, top_p=1, n=1, stop=['.','\\n'])\n",
    "    return result['choices'][0]['text']\n",
    "\n",
    "apply_ft_qa_answer('ABCD', \n",
    "                    'What?', ft_qa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model can answer the question, when the context is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Soviet Union was the first country to successfully launch a satellite into space'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_ft_qa_answer('ABCD',\n",
    "                    'What?', ft_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' No appropriate context found to answer the question'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_ft_qa_answer('ABCD',\n",
    "                    'How many?', ft_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model knows when to answer the question, and when to say that insufficient context is present to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine a discriminator and a base model, or a fine-tuned Q&A model. Discriminator can essentially serve as a decision whether the question can be answered given the context or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Weather could cause a sport event to have no crowd'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_question_conditionally(answering_model, discriminator_model, context, question, discriminator_logprob_yes_modifier=0):\n",
    "    logprobs = apply_ft_discriminator(context, question, discriminator_model)\n",
    "    yes_logprob = logprobs[' yes'] if ' yes' in logprobs else -100\n",
    "    no_logprob = logprobs[' no'] if ' no' in logprobs else -100\n",
    "    if yes_logprob + discriminator_logprob_yes_modifier < no_logprob:\n",
    "        return \" No appropriate context found to answer the question based on the discriminator.\"\n",
    "    return apply_ft_qa_answer(context, question, answering_model)\n",
    "answer_question_conditionally(ft_qa, ft_discriminator, \n",
    "                                \"ABCD.\",\n",
    "                                \"why?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function illustrates how to potentially combine a discriminator and a fine-tuned Q&A model. This gives a more fine-grained control over how certain we want the model to be before it answers the question.\n",
    "\n",
    "We'll now take a look on how answers endpoint works - combining search to retrieve the relevant context from a knowledge base, and then using the fine-tuned Q&A model to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Answering the question based on a knowledge base\n",
    "Finally we can use a logic similar to the [/answers](https://beta.openai.com/docs/api-reference/answers) endpoint, where we first search for the relevant context, and then ask a Q&A model to answer the question given that context. If you'd like to see the implementation details, check out the [`answers_with_ft.py`](answers_with_ft.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Canada won the Women's football tournament at the 2020 Olympic games\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from answers_with_ft import answer_question\n",
    "answer_question(olympics_search_fileid, ft_qa, \"What?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb9817b186a29e4e9713184d901f26c1ee05ad25243d878baff7f31bb1fef480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
